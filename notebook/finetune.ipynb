{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d701919-69fb-4421-a8d8-1e71f6359d46",
   "metadata": {},
   "source": [
    "# Load Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32646941-d11f-4fc9-9712-7902ff5a67c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "edbf632e-b2bf-45ad-bca8-24824e3732c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.current_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56ce5561-19d1-4147-abae-8de918d80b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "os.environ[\"WANDB_MODE\"] = \"offline\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df39fbbf-150a-4b75-8b28-214b317f9455",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad289ea0-786d-4b19-b9b9-ff59b4777534",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚙️  Running in WANDB offline mode\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import transformers\n",
    "from transformers import (AutoModelForCausalLM,\n",
    "                          AutoTokenizer,\n",
    "                          BitsAndBytesConfig,\n",
    "                          TrainingArguments,\n",
    "                          pipeline,\n",
    "                          logging)\n",
    "from datasets import Dataset\n",
    "from peft import LoraConfig, PeftConfig\n",
    "import bitsandbytes as bnb\n",
    "from trl import SFTTrainer\n",
    "\n",
    "from sklearn.metrics import (accuracy_score,\n",
    "                             classification_report,\n",
    "                             confusion_matrix)\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22bbc71c-e3b2-4858-be66-75c4e3a438b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import logging\n",
    "\n",
    "logging.set_verbosity_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b35e3162-6fa9-428d-8751-415788739b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, DatasetDict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2da7361-f8b5-40b7-98dd-1cdeed64739e",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0096e946-d758-477d-a885-33431a65ece0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_dataset('../dataset/thai-sentiment/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb4c03f5-429d-4e8b-b784-79874d389853",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['label', 'text'],\n",
       "        num_rows: 500\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['label', 'text'],\n",
       "        num_rows: 100\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['label', 'text'],\n",
       "        num_rows: 200\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cfe75c2e-e0b6-4886-9f1b-ebef583e8e5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': 0,\n",
       " 'text': 'อยากได้ลิปรววแต่กูไม่ไหวใจอีทูดี้ละ การที่คิ้วกูหายระหว่างวันแม่งไม่ตลก'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['train'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a9ea90-aa7f-48da-b48b-dc31c469b161",
   "metadata": {},
   "source": [
    "# Data PreProcess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1cdc5172-f8b5-4a85-ab69-a4ce43eeff50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prompt(data_point):\n",
    "    return f\"\"\"\n",
    "            Analyze the sentiment of the tweet enclosed in square brackets,\n",
    "            determine if it is positive or negative, and return the answer as\n",
    "            the corresponding sentiment label \"positive\" or  \"negative\"\n",
    "\n",
    "            [{data_point[\"text\"]}] = {data_point[\"label\"]}\n",
    "            \"\"\".strip()\n",
    "\n",
    "def generate_test_prompt(data_point):\n",
    "    return f\"\"\"\n",
    "            Analyze the sentiment of the tweet enclosed in square brackets,\n",
    "            determine if it is positive or negative, and return the answer as\n",
    "            the corresponding sentiment label \"positive\" or  \"negative\"\n",
    "\n",
    "            [{data_point[\"text\"]}] =\n",
    "\n",
    "            \"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c38ebacd-a398-41fe-9f0a-00a276e98561",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = data['test'].to_pandas()\n",
    "validation = data['validation'].to_pandas()\n",
    "train = data['train'].to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "37ed7d97-668b-4fdb-903b-4d5b20d830bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(x):\n",
    "    if x==1:\n",
    "        return 'positive'\n",
    "    elif x==0:\n",
    "        return 'negative'\n",
    "    else:\n",
    "        return 'none'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f4ffb863-c76a-4535-b3c5-b8fe987ee4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['label'] = train['label'].apply(lambda x: convert(x))\n",
    "validation['label'] = validation['label'].apply(lambda x: convert(x))\n",
    "test['label'] = test['label'].apply(lambda x: convert(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5511857f-407e-44b9-b34e-470d1eed69c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>negative</td>\n",
       "      <td>อยากได้ลิปรววแต่กูไม่ไหวใจอีทูดี้ละ การที่คิ้ว...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positive</td>\n",
       "      <td>คัดจนเกลี้ยง</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>negative</td>\n",
       "      <td>=+10 กุ้งเทมปูระ ก็แหม่งๆรสชาติแปลกๆไปเหมือนกั...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>positive</td>\n",
       "      <td>ดีพอใจมากครับ เบรคนุ่มไปไกลๆมาแล้วเบรคมั่นใจ ข...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>negative</td>\n",
       "      <td>ไม่โอเคกับการเมาแสงโสมเลยอะ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                               text\n",
       "0  negative  อยากได้ลิปรววแต่กูไม่ไหวใจอีทูดี้ละ การที่คิ้ว...\n",
       "1  positive                                       คัดจนเกลี้ยง\n",
       "2  negative  =+10 กุ้งเทมปูระ ก็แหม่งๆรสชาติแปลกๆไปเหมือนกั...\n",
       "3  positive  ดีพอใจมากครับ เบรคนุ่มไปไกลๆมาแล้วเบรคมั่นใจ ข...\n",
       "4  negative                        ไม่โอเคกับการเมาแสงโสมเลยอะ"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb50907-1b96-42f5-9de3-d27ecb9f01bb",
   "metadata": {},
   "source": [
    "# Apply Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a6c4e48d-214c-438b-b2df-84ef675c0e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.DataFrame(train.apply(generate_prompt, axis=1),\n",
    "                       columns=[\"text\"])\n",
    "X_eval = pd.DataFrame(validation.apply(generate_prompt, axis=1),\n",
    "                      columns=[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9ef75f24-7182-413b-9547-456cddf82713",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = test.label\n",
    "X_test = pd.DataFrame(test.apply(generate_test_prompt, axis=1), columns=[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "400c64de-a193-4a50-a10b-02cce45b71a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = Dataset.from_pandas(X_train)\n",
    "eval_data = Dataset.from_pandas(X_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "14c5603e-4b90-46ae-9e0a-20aabfff0e5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyze the sentiment of the tweet enclosed in square brackets,\n",
      "            determine if it is positive or negative, and return the answer as\n",
      "            the corresponding sentiment label \"positive\" or  \"negative\"\n",
      "\n",
      "            [อยากได้ลิปรววแต่กูไม่ไหวใจอีทูดี้ละ การที่คิ้วกูหายระหว่างวันแม่งไม่ตลก] = negative\n"
     ]
    }
   ],
   "source": [
    "print(train_data['text'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d318bbce-d75b-4f01-8255-1f7df7d7891c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyze the sentiment of the tweet enclosed in square brackets,\n",
      "            determine if it is positive or negative, and return the answer as\n",
      "            the corresponding sentiment label \"positive\" or  \"negative\"\n",
      "\n",
      "            [เดี๋ยวเจอ 285 ขนาดยังไม่แดกกูก็รู้สึกปวดหัวละ 55] = negative\n"
     ]
    }
   ],
   "source": [
    "print(eval_data['text'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "df61a413-9309-4050-a897-919e372be4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(y_true, y_pred):\n",
    "\n",
    "    labels = ['positive',  'negative']\n",
    "    mapping = {'positive': 1, 'negative': 0, 'none':1,}\n",
    "    def map_func(x):\n",
    "        return mapping.get(x, 1)\n",
    "\n",
    "    y_true = np.vectorize(map_func)(y_true)\n",
    "    y_pred = np.vectorize(map_func)(y_pred)\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_true=y_true, y_pred=y_pred)\n",
    "    print(f'Accuracy: {accuracy:.3f}')\n",
    "\n",
    "    # Generate accuracy report\n",
    "    unique_labels = set(y_true)  # Get unique labels\n",
    "\n",
    "    for label in unique_labels:\n",
    "        label_indices = [i for i in range(len(y_true))\n",
    "                         if y_true[i] == label]\n",
    "        label_y_true = [y_true[i] for i in label_indices]\n",
    "        label_y_pred = [y_pred[i] for i in label_indices]\n",
    "        accuracy = accuracy_score(label_y_true, label_y_pred)\n",
    "        print(f'Accuracy for label {label}: {accuracy:.3f}')\n",
    "\n",
    "    # Generate classification report\n",
    "    class_report = classification_report(y_true=y_true, y_pred=y_pred)\n",
    "    print('\\nClassification Report:')\n",
    "    print(class_report)\n",
    "\n",
    "    # Generate confusion matrix\n",
    "    conf_matrix = confusion_matrix(y_true=y_true, y_pred=y_pred, labels=[0, 1])\n",
    "    print('\\nConfusion Matrix:')\n",
    "    print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "61b0bdd6-7bae-4c54-ab86-e93fdb961a78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "028cd73ffd1b4c67b92dabb3c6adfd19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = \"../model/llama-Meta-Llama-3-8B-Instruct/\" #Qwen/Qwen3-1.7B #Qwen/Qwen2.5-1.5B\n",
    "\n",
    "compute_dtype = getattr(torch, \"float16\")\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=False,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=compute_dtype,\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    device_map=\"auto\",\n",
    "    quantization_config=bnb_config,\n",
    ")\n",
    "\n",
    "model.config.use_cache = False\n",
    "model.config.pretraining_tp = 1\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "779f04e0-ec6d-4c1f-80c7-a258549b1dbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(128256, 4096)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "          (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "          (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "          (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "          (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "        (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "    (rotary_emb): LlamaRotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=128256, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f42af55-ae8a-48cc-a28a-ea3c4fabea0d",
   "metadata": {},
   "source": [
    "# Predoct Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dbc75596-3bc0-4c0f-b837-50db60ad21a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X_test, model, tokenizer):\n",
    "    y_pred = []\n",
    "    for i in tqdm(range(len(X_test))):\n",
    "        prompt = X_test.iloc[i][\"text\"]\n",
    "        input_ids = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "        outputs = model.generate(**input_ids, max_new_tokens=1, temperature=0.0,\n",
    "                                 pad_token_id=tokenizer.eos_token_id, do_sample=False)\n",
    "        result = tokenizer.decode(outputs[0])\n",
    "        answer = result.split(\"=\")[-1].lower()\n",
    "        if \"positive\" in answer:\n",
    "            y_pred.append(\"positive\")\n",
    "        elif \"negative\" in answer:\n",
    "            y_pred.append(\"negative\")\n",
    "        elif \"neutral\" in answer:\n",
    "            y_pred.append(\"neutral\")\n",
    "        else:\n",
    "            y_pred.append(\"none\")\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3c071142-14e6-41e6-a6f2-c314bca0c2c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:20<00:00,  9.94it/s]\n"
     ]
    }
   ],
   "source": [
    "y_pred = predict(X_test , model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "629ea711-7cf6-4821-83eb-d30fb2ae8d0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.415\n",
      "Accuracy for label 0: 0.017\n",
      "Accuracy for label 1: 1.000\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.02      0.03       119\n",
      "           1       0.41      1.00      0.58        81\n",
      "\n",
      "    accuracy                           0.41       200\n",
      "   macro avg       0.70      0.51      0.31       200\n",
      "weighted avg       0.76      0.41      0.25       200\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[  2 117]\n",
      " [  0  81]]\n"
     ]
    }
   ],
   "source": [
    "evaluate(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a149b7c7-aa08-43eb-b8a9-6172343ab7a6",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "88d94621-e33b-4e90-bef2-7385cb9a0be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(text, model, tokenizer):\n",
    "    prompt = f\"\"\"\n",
    "            Analyze the sentiment of the tweet enclosed in square brackets,\n",
    "            determine if it is positive or negative, and return the answer as\n",
    "            the corresponding sentiment label \"positive\" or  \"negative\"\n",
    "\n",
    "            [{text}] =\n",
    "\n",
    "            \"\"\".strip()\n",
    "    input_ids = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "    outputs = model.generate(**input_ids, max_new_tokens=1, temperature=0.01)\n",
    "    result = tokenizer.decode(outputs[0])\n",
    "    answer = result.split(\"=\")[-1].lower().strip()\n",
    "\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "09e237a3-0fb9-4520-955a-8bc9e3767136",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inference('แฟนบอกว่าไม่เป็นไรหรอก คิดมาก', model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e4060819-34cf-4905-b13d-9d4280b5d309",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text'],\n",
       "    num_rows: 500\n",
       "})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cafca1fd-adbd-4c27-a905-afbb078f3f6f",
   "metadata": {},
   "source": [
    "# FineTune with LoRa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "159e4c8e-da92-4720-ac2f-6bb4c53790b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8e24348cee64234945a4daca88ba5be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding EOS to train dataset:   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88ad909762ee4785bf1deaa37643c8d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing train dataset:   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28a3004e18ae4f53a103e0f3042d7574",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Truncating train dataset:   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "peft_config = LoraConfig(\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.1,\n",
    "    r=64,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    target_modules=\"all-linear\",\n",
    ")\n",
    "\n",
    "training_arguments = TrainingArguments(\n",
    "    output_dir=\"logs\",\n",
    "    num_train_epochs=2,\n",
    "    per_device_train_batch_size=2,\n",
    "    gradient_accumulation_steps=4,\n",
    "    gradient_checkpointing=False,\n",
    "    optim=\"paged_adamw_8bit\",\n",
    "    save_steps=0,\n",
    "    logging_steps=25,\n",
    "    learning_rate=2e-4,\n",
    "    weight_decay=0.001,\n",
    "    fp16=True,\n",
    "    bf16=False,\n",
    "    max_grad_norm=0.3,\n",
    "    max_steps=-1,\n",
    "    warmup_ratio=0.03,\n",
    "    group_by_length=True,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    do_eval=False,\n",
    ")\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=train_data,\n",
    "    peft_config=peft_config,\n",
    "    args=training_arguments,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7dd0bbc4-8f50-473a-884a-a76c6e554b4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(128256, 4096)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): lora.Linear4bit(\n",
       "            (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "            (lora_dropout): ModuleDict(\n",
       "              (default): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (lora_A): ModuleDict(\n",
       "              (default): Linear(in_features=4096, out_features=64, bias=False)\n",
       "            )\n",
       "            (lora_B): ModuleDict(\n",
       "              (default): Linear(in_features=64, out_features=4096, bias=False)\n",
       "            )\n",
       "            (lora_embedding_A): ParameterDict()\n",
       "            (lora_embedding_B): ParameterDict()\n",
       "            (lora_magnitude_vector): ModuleDict()\n",
       "          )\n",
       "          (k_proj): lora.Linear4bit(\n",
       "            (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "            (lora_dropout): ModuleDict(\n",
       "              (default): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (lora_A): ModuleDict(\n",
       "              (default): Linear(in_features=4096, out_features=64, bias=False)\n",
       "            )\n",
       "            (lora_B): ModuleDict(\n",
       "              (default): Linear(in_features=64, out_features=1024, bias=False)\n",
       "            )\n",
       "            (lora_embedding_A): ParameterDict()\n",
       "            (lora_embedding_B): ParameterDict()\n",
       "            (lora_magnitude_vector): ModuleDict()\n",
       "          )\n",
       "          (v_proj): lora.Linear4bit(\n",
       "            (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "            (lora_dropout): ModuleDict(\n",
       "              (default): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (lora_A): ModuleDict(\n",
       "              (default): Linear(in_features=4096, out_features=64, bias=False)\n",
       "            )\n",
       "            (lora_B): ModuleDict(\n",
       "              (default): Linear(in_features=64, out_features=1024, bias=False)\n",
       "            )\n",
       "            (lora_embedding_A): ParameterDict()\n",
       "            (lora_embedding_B): ParameterDict()\n",
       "            (lora_magnitude_vector): ModuleDict()\n",
       "          )\n",
       "          (o_proj): lora.Linear4bit(\n",
       "            (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "            (lora_dropout): ModuleDict(\n",
       "              (default): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (lora_A): ModuleDict(\n",
       "              (default): Linear(in_features=4096, out_features=64, bias=False)\n",
       "            )\n",
       "            (lora_B): ModuleDict(\n",
       "              (default): Linear(in_features=64, out_features=4096, bias=False)\n",
       "            )\n",
       "            (lora_embedding_A): ParameterDict()\n",
       "            (lora_embedding_B): ParameterDict()\n",
       "            (lora_magnitude_vector): ModuleDict()\n",
       "          )\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): lora.Linear4bit(\n",
       "            (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "            (lora_dropout): ModuleDict(\n",
       "              (default): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (lora_A): ModuleDict(\n",
       "              (default): Linear(in_features=4096, out_features=64, bias=False)\n",
       "            )\n",
       "            (lora_B): ModuleDict(\n",
       "              (default): Linear(in_features=64, out_features=14336, bias=False)\n",
       "            )\n",
       "            (lora_embedding_A): ParameterDict()\n",
       "            (lora_embedding_B): ParameterDict()\n",
       "            (lora_magnitude_vector): ModuleDict()\n",
       "          )\n",
       "          (up_proj): lora.Linear4bit(\n",
       "            (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "            (lora_dropout): ModuleDict(\n",
       "              (default): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (lora_A): ModuleDict(\n",
       "              (default): Linear(in_features=4096, out_features=64, bias=False)\n",
       "            )\n",
       "            (lora_B): ModuleDict(\n",
       "              (default): Linear(in_features=64, out_features=14336, bias=False)\n",
       "            )\n",
       "            (lora_embedding_A): ParameterDict()\n",
       "            (lora_embedding_B): ParameterDict()\n",
       "            (lora_magnitude_vector): ModuleDict()\n",
       "          )\n",
       "          (down_proj): lora.Linear4bit(\n",
       "            (base_layer): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
       "            (lora_dropout): ModuleDict(\n",
       "              (default): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (lora_A): ModuleDict(\n",
       "              (default): Linear(in_features=14336, out_features=64, bias=False)\n",
       "            )\n",
       "            (lora_B): ModuleDict(\n",
       "              (default): Linear(in_features=64, out_features=4096, bias=False)\n",
       "            )\n",
       "            (lora_embedding_A): ParameterDict()\n",
       "            (lora_embedding_B): ParameterDict()\n",
       "            (lora_magnitude_vector): ModuleDict()\n",
       "          )\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "        (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "    (rotary_emb): LlamaRotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=128256, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9e940ec4-2855-48bb-8013-1e61e023b4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"WANDB_MODE\"] = \"offline\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6dc5bcf4-5630-4496-bb82-2cb352faa9bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.9227, 'grad_norm': 0.4714037775993347, 'learning_rate': 0.00018702852410301554, 'entropy': 2.0744064939022064, 'num_tokens': 17931.0, 'mean_token_accuracy': 0.6533071425557136, 'epoch': 0.4}\n",
      "{'loss': 1.2449, 'grad_norm': 0.6389788389205933, 'learning_rate': 0.00014004539056512667, 'entropy': 1.4031887224316597, 'num_tokens': 34860.0, 'mean_token_accuracy': 0.7601819917559623, 'epoch': 0.8}\n",
      "{'loss': 1.0982, 'grad_norm': 0.4026164412498474, 'learning_rate': 7.703122578682046e-05, 'entropy': 1.2945905805242306, 'num_tokens': 50700.0, 'mean_token_accuracy': 0.7813233623699266, 'epoch': 1.192}\n",
      "{'loss': 1.0709, 'grad_norm': 0.5453364849090576, 'learning_rate': 2.3211955396340002e-05, 'entropy': 1.183849729001522, 'num_tokens': 68264.0, 'mean_token_accuracy': 0.7834264385700226, 'epoch': 1.592}\n",
      "{'loss': 0.9212, 'grad_norm': 0.6280507445335388, 'learning_rate': 1.3259101151694708e-07, 'entropy': 1.0929750800132751, 'num_tokens': 83546.0, 'mean_token_accuracy': 0.8091595894098282, 'epoch': 1.992}\n",
      "{'train_runtime': 130.6997, 'train_samples_per_second': 7.651, 'train_steps_per_second': 0.964, 'train_loss': 1.2457847131623163, 'entropy': 0.6650262176990509, 'num_tokens': 83786.0, 'mean_token_accuracy': 0.8774086833000183, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=126, training_loss=1.2457847131623163, metrics={'train_runtime': 130.6997, 'train_samples_per_second': 7.651, 'train_steps_per_second': 0.964, 'train_loss': 1.2457847131623163, 'entropy': 0.6650262176990509, 'num_tokens': 83786.0, 'mean_token_accuracy': 0.8774086833000183, 'epoch': 2.0})"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db27c0b-95db-4a2f-aa50-3247f008119e",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "682f3350-7ed5-42c6-9dc0-153cce7c9a8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:20<00:00,  9.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.885\n",
      "Accuracy for label 0: 0.899\n",
      "Accuracy for label 1: 0.864\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.90      0.90       119\n",
      "           1       0.85      0.86      0.86        81\n",
      "\n",
      "    accuracy                           0.89       200\n",
      "   macro avg       0.88      0.88      0.88       200\n",
      "weighted avg       0.89      0.89      0.89       200\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[107  12]\n",
      " [ 11  70]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = predict(X_test, model, tokenizer)\n",
    "evaluate(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "07bc1bfb-a7db-4a10-ac5f-88fa45dd9e58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'negative'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inference('แฟนบอกว่าไม่เป็นไรหรอก คิดมาก', model, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b91655d-8c4c-4c77-a088-adb42980c40c",
   "metadata": {},
   "source": [
    "# Save Adapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "62f9c2de-1e17-476c-bbb2-569a25ec75e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.model.save_pretrained(\"../train_model/adapter-sentiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0b7a54-b188-4b79-bb0b-7670d8b7e2e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
